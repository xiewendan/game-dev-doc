[TOC]

------------------------------------------------------------------------------
# 1. 1 问题
在扫档的时候，先把功能实现了，后来运行的时候，发现时间太久了，开始了优化之路




------------------------------------------------------------------------------
# 2. 2 思路

* 对于mongo不熟悉，借助gpt了解常见的优化策略
* 针对每个优化策略，在自己的扫档脚本上面，进行优化尝试



------------------------------------------------------------------------------
# 3. 3 解决方案

## 3.1. 常见优化策略
* 读写数据库
  * 分片
  * 创建index
  * 批量操作
  * 投影获取数据
* 导入导出数据库
  * 部分导入
  * 多进程导入

## 3.2. 统计数据

### 3.2.1. 读写数据库
* 分片：无
* 创建index：2.16 -> 3.9
  * 2.1674306392669678
  * 3.9052207469940186
* 批量操作
  * 一共51000条，从一个表拷贝到另一个表120秒，用insert_many, 只需要2秒
  * 所有表中的player guid转换：1200秒->152秒
    * update_one():1200秒
    * bulk_write() 确保插入和删除要连续：152秒
* 投影获取数据：
  一个5万条数据：113秒（没投影）->108秒（有投影）
  相差不大，可能字段太少了
### 3.2.2. 导入导出数据库
* 部分导入
  * 在前期测试扫档的时候，主要是流程性的代码验证，因此只需要部分数据即可验证，这时候，使用部分导入即可，可以极大加快mongorestore数据库的速度
  * 实际操作：将需要导入的数据，单独放到一个文件夹，mongorestore这个文件夹即可
    ~~~sh
    mongorestore "mongodb://用户名:密码@分片1Ip:端口,分片2Ip:端口/数据库名" 包含部分数据的文件夹
    ~~~
* 多进程导入
  * 在导入的时候， 发现比较慢，mongo的默认参数比较保守，因此需要调整参数
    ~~~
    mongorestore --numInsertionWorkersPerCollection 8 --numParallelCollections 8 --batchSize 100  "mongodb://用户名:密码@分片1ip:端口,分片2ip:端口/数据" 目录
    ~~~
    * --numInsertionWorkersPerCollection：单个collection支持的进程数，通常对于单表大数据，效果比较明显，默认值是4
    * --numParallelCollections：并行导入的collection个数，通常对于表格特别多，效果比较明显，默认值是4
    * --batchsize：批量处理大小，默认内部有算法动态计算，不指定效果会比较好
  * 统计数据
    ~~~s
    1、没有参数：是210秒, 260
      2024-01-28T18:15:24.240+0800
      2024-01-28T18:18:55.671+0800

    2、--batchSize 100（由内部算法默认计算得到）680

    3、--numParallelCollections 8 （默认值是4） 210
      2024-01-28T18:39:15.728+0800
      2024-01-28T18:42:54.690+0800

    4、--numInsertionWorkersPerCollection 8（默认值是4）120
      2024-01-28T18:32:18.907+0800
      2024-01-28T18:34:19.174+0800
    ~~~

  
* 完整指令
    ~~~
    连接数据库：mongo "mongodb://用户名:密码@分片1Ip:端口,分片2Ip:端口/数据库名"
    备份数据库：mongodump "mongodb://用户名:密码@分片1Ip:端口,分片2Ip:端口/数据库名" --out /home/data/
    恢复数据库：mongorestore "mongodb://用户名:密码@分片1Ip:端口,分片2Ip:端口/数据库名" /home/data/数据库名
    ~~~

------------------------------------------------------------------------------
# 4. 4 结论

| 优化技术 | 不使用 | 使用 | 推荐 |
| :-----| ----: | :----: | :----: |
| index | 2.16 | 3.9 | &#9733;&#9733;&#9733;&#9733;&#9734; |
| 批处理 | 1200 | 150 | &#9733;&#9733;&#9733;&#9733;&#9734; |
| 投影  |  113 | 108 | &#9733;&#9734;&#9734;&#9734;&#9734; |

> 以上数据只针对当前测试数据，投影效果，可能会跟数据相关
> index的数据有点奇怪，需要看一下原理


| 优化参数 | 不使用 | 使用 | 推荐 |
| :-----| ----: | :----: | :----: |
| batchsize | 260 | 680 | &#9734;&#9734;&#9734;&#9734;&#9734; | 
| numParallelCollections | 260 | 210 | &#9733;&#9733;&#9733;&#9743;&#9734; |
| numInsertionWorkersPerCollection | 260 | 120 | &#9733;&#9733;&#9733;&#9733;&#9734; |



------------------------------------------------------------------------------
# 5. 5 展望

* 了解数据库的内部实现核心算法，了解为什么index特别快



------------------------------------------------------------------------------
# 6. 6 文献


